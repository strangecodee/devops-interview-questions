# kubernetes â€” Sat Dec  6 14:42:48 UTC 2025

**Random Topic of the Minute:** Zero-Downtime Deploys

Okay, let's create a Kubernetes deployment YAML that focuses on zero-downtime deployments, seeded with 1765032154.  This will involve configuring `strategy.type` (RollingUpdate) and the `strategy.rollingUpdate` parameters (`maxSurge` and `maxUnavailable`) to control how deployments are handled.

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-deployment
  labels:
    app: my-app
spec:
  replicas: 3  # Start with 3 replicas for redundancy
  selector:
    matchLabels:
      app: my-app
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%    # Allow 25% more pods than desired during update
      maxUnavailable: 25%  # Allow 25% of pods to be unavailable during update
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app-container
        image: your-docker-registry/my-app:v1  # Replace with your image
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /healthz  # Basic health endpoint
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: LoadBalancer  # Or NodePort/ClusterIP depending on your environment

```

**Explanation:**

1.  **`apiVersion: apps/v1` and `kind: Deployment`**: Defines this resource as a Deployment, which manages replicated application instances.

2.  **`metadata`**:  Specifies the name and labels for the deployment.  Labels are used for service discovery and selecting pods.

3.  **`spec.replicas: 3`**: This defines the desired number of pod replicas.  Having multiple replicas is critical for zero-downtime deployments. If one pod goes down during an update, the other replicas can still serve traffic.

4.  **`spec.selector`**:  Defines how the Deployment identifies the Pods it manages.  Pods with the label `app: my-app` will be controlled by this Deployment.

5.  **`spec.strategy`**: This is the heart of the zero-downtime deployment.

    *   **`type: RollingUpdate`**:  Specifies that the Deployment will use a RollingUpdate strategy. This means that old Pods will be gradually replaced with new Pods, instead of all old Pods being terminated at once.

    *   **`rollingUpdate`**:  Configures the RollingUpdate strategy.

        *   **`maxSurge: 25%`**:  Determines the maximum number of Pods that can be created *above* the desired number of replicas during an update.  `25%` means that Kubernetes can create up to `0.25 * 3 = 0.75`, rounded up to `1`, additional Pod during the update.  So, you could temporarily have 4 pods.  This helps ensure that there's always enough capacity to handle traffic.  You can also specify an integer value (e.g., `maxSurge: 1`).

        *   **`maxUnavailable: 25%`**: Determines the maximum number of Pods that can be *unavailable* during the update. `25%` means Kubernetes can take down `0.25 * 3 = 0.75` Pods, rounded down to 0, during the update without breaking the deployment.  You can also specify an integer value (e.g., `maxUnavailable: 1`). Crucially, this should be less than the number of replicas for a zero-downtime deploy.

6.  **`spec.template`**:  Defines the Pod template, which describes how each Pod in the Deployment should be configured.

    *   **`metadata.labels`**: The labels that will be applied to the Pods created by this Deployment.

    *   **`spec.containers`**:  Defines the container(s) that will run inside the Pod.

        *   **`name`**: The name of the container.
        *   **`image`**: The Docker image to use for the container.  **Replace `your-docker-registry/my-app:v1` with your actual Docker image.**
        *   **`ports`**: The ports that the container exposes.
        *   **`livenessProbe`**:  A probe that checks if the container is running and healthy. If the probe fails, Kubernetes will restart the container.
        *   **`readinessProbe`**:  A probe that checks if the container is ready to serve traffic. If the probe fails, Kubernetes will stop sending traffic to the container. This is crucial for zero-downtime deployments because it ensures that traffic is only sent to healthy containers.

        *   **`resources`**: Define the resource requests and limits for the container.  Request is what the container is guaranteed, limit is the maximum it can consume.

7.  **`Service` (service.yaml)**:

    *   **`apiVersion: v1` and `kind: Service`**: Defines a Kubernetes Service.
    *   **`metadata.name`**:  The name of the service.
    *   **`spec.selector`**:  Selects the Pods that this Service will route traffic to.  It uses the same label as the Deployment's `matchLabels`.
    *   **`spec.ports`**:  Defines the ports that the Service exposes.
        *   `port`: The port on which the Service listens.
        *   `targetPort`: The port on the Pod that the Service forwards traffic to.
    *   **`spec.type`**: The type of Service. `LoadBalancer` provisions an external load balancer (if supported by your cloud provider).  `NodePort` exposes the service on each node's IP at a static port. `ClusterIP` exposes the service on a cluster-internal IP.  Choose the type that is appropriate for your environment.

**How it achieves zero-downtime:**

1.  **Rolling Updates:** The `RollingUpdate` strategy ensures that new versions of the application are deployed gradually, replacing old versions one at a time.

2.  **Replicas:** Having multiple replicas ensures that there are always Pods available to handle traffic, even during an update.

3.  **`maxSurge`:**  Allows for the creation of extra Pods, which helps to maintain capacity during the update.

4.  **`maxUnavailable`:**  Controls how many Pods can be unavailable during the update.  By keeping this low, we minimize the impact on users.

5.  **`readinessProbe`:**  Ensures that traffic is only sent to Pods that are ready to handle it.  Kubernetes won't send traffic to a Pod until its readiness probe passes.

6.  **Service**: Provides a stable endpoint for clients to access the application, regardless of which Pod is currently serving traffic.

**How to deploy:**

1.  Save the above YAML as `deployment.yaml` and `service.yaml` (or separate files, `service.yaml` is optional and depends if you already have a running service).
2.  Replace `your-docker-registry/my-app:v1` with your actual Docker image.
3.  Apply the deployment and service:

    ```bash
    kubectl apply -f deployment.yaml
    kubectl apply -f service.yaml
    ```

4.  To update the deployment to a new version (e.g., `your-docker-registry/my-app:v2`), simply change the `image` in `deployment.yaml` and re-apply it:

    ```bash
    kubectl apply -f deployment.yaml
    ```

Kubernetes will then perform a rolling update, gradually replacing the old Pods with the new Pods. You can monitor the progress of the update using `kubectl rollout status deployment/my-app-deployment`.

**Important Considerations:**

*   **Health Checks:**  The `livenessProbe` and `readinessProbe` are *essential*.  Make sure your application exposes a `/healthz` (or similar) endpoint that accurately reflects its health and readiness to serve traffic.
*   **Graceful Shutdown:**  Ensure your application handles shutdown signals (e.g., `SIGTERM`) gracefully and completes in-flight requests before terminating.  This minimizes request failures during the update. The `terminationGracePeriodSeconds` parameter in the pod spec (defaults to 30s) controls how long Kubernetes waits for a pod to shutdown before forcefully killing it.
*   **Traffic Management:**  Consider using more advanced traffic management techniques (e.g., Canary Deployments, Blue/Green Deployments) for more complex deployment scenarios. These can be implemented with tools like Istio or Argo Rollouts.
*   **Monitoring:**  Monitor your application's health and performance during and after deployments to ensure that the update is successful and that there are no unexpected issues.
*   **Database Migrations:**  If your application requires database migrations, carefully plan how to execute them without causing downtime.  Often, migrations should be run *before* the new application version is deployed.
*   **Session Handling:** If your application uses sessions, ensure that sessions are properly handled during deployments. Options include sticky sessions (less ideal for HA), session replication, or a shared session store.
*   **Dependencies:** Consider dependencies on external services or databases.  Ensure these are available and that the new version is compatible.
*   **Resource Limits:** Properly configure resource requests and limits for your containers to prevent resource contention and ensure that your application has enough resources to run properly.  The example includes `resources` which helps with scheduling and stability.
*   **NetworkPolicy:** Enforce network policies to restrict traffic flow within the cluster and enhance security.

This example provides a basic but effective foundation for achieving zero-downtime deployments in Kubernetes.  Customize it based on the specific requirements of your application.
